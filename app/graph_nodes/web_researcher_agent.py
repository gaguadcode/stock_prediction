from langchain_community.document_loaders import WikipediaLoader
from langchain_ollama import OllamaLLM
from app.graph_nodes.model_inference import GradientBoostingWorkflow  # Import Gradient Boosting Workflow
from app.graph_nodes.stock_fetch_data import HistoricalDataFetcher  # Import the HistoricalDataFetcher
from app.utils.logger import get_logger
import pandas as pd


class StockResearchAgent:
    """
    A class to perform stock research by fetching Wikipedia summaries, fetching historical data,
    running machine learning workflows, and generating detailed responses using LangChain's OllamaLLM integration.
    """

    def __init__(self, model_name="llama2"):
        """
        Initialize the StockResearchAgent with the Ollama model name, a HistoricalDataFetcher,
        and a GradientBoostingWorkflow instance.

        Args:
            model_name (str): The name of the Ollama model to use. Default is 'llama2'.
        """
        self.logger = get_logger(self.__class__.__name__)  # Initialize logger
        self.model_name = model_name
        self.logger.info(f"Initializing StockResearchAgent with model '{model_name}'")
        self.llm = OllamaLLM(model=model_name)
        self.workflow = GradientBoostingWorkflow(granularity='monthly', date_column='date', target_column='price')
        self.data_fetcher = HistoricalDataFetcher()

    def fetch_wikipedia_data(self, stock_name):
        """
        Fetch a summary of the given stock name from Wikipedia.
        """
        try:
            self.logger.info(f"Fetching Wikipedia data for: {stock_name}")
            loader = WikipediaLoader(query=stock_name, load_max_docs=1)
            docs = loader.load()
            if docs:
                summary = docs[0].metadata.get("summary", "No summary available.")
                self.logger.debug(f"Wikipedia summary fetched: {summary}")
                return summary
            else:
                self.logger.warning(f"No Wikipedia page found for stock: {stock_name}")
                return "No Wikipedia page found for this stock."
        except Exception as e:
            self.logger.error(f"Error fetching Wikipedia data: {e}")
            return f"Error fetching data: {e}"

    def generate_response(self, stock_name, wikipedia_summary, mse, predictions):
        """
        Generate a detailed response using Wikipedia data and Gradient Boosting predictions.

        Args:
            stock_name (str): The stock name for context.
            wikipedia_summary (str): The fetched Wikipedia summary.
            mse (float): The Mean Squared Error from the model evaluation.
            predictions (list): The predictions generated by the Gradient Boosting model.

        Returns:
            str: The detailed response combining Wikipedia data and workflow results.
        """
        self.logger.info(f"Generating response for stock: {stock_name}")
        prompt = f"""
        You are an expert financial researcher. Based on the following information, provide a detailed analysis of {stock_name}:

        Wikipedia Summary:
        {wikipedia_summary}

        Machine Learning Results:
        - Mean Squared Error (MSE): {mse}
        - Predicted Future Prices: {predictions}

        Provide an insightful analysis of the company's historical significance, its stock trends, and the predicted performance.
        """
        try:
            response = self.llm.invoke(prompt)
            self.logger.debug(f"Generated response: {response}")
            return response
        except Exception as e:
            self.logger.error(f"Error generating response: {e}")
            return f"Error generating response: {e}"

    async def run(self, agent_output):
        """
        Executes the stock research workflow, fetching data, combining Wikipedia and ML results.

        Args:
            agent_output (dict): The dictionary output from the previous class (e.g., NaturalLanguageProcessor).

        Returns:
            dict: A dictionary containing the original agent_output fields and an additional 'generative_response'.
        """
        try:
            self.logger.info("Starting StockResearchAgent workflow...")

            # Step 1: Fetch Historical Data
            self.logger.info("Fetching historical stock data...")
            validated_output = await self.data_fetcher.fetch_and_save_historical_data(agent_output)
            self.logger.info("Historical data fetched successfully.")

            # Load historical data from CSV for machine learning
            ml_training_data = pd.read_csv(self.data_fetcher.output_data)
            self.logger.debug(f"Loaded historical data:\n{ml_training_data.head()}")

            # Extract the `date_target` field and prepare it as `ml_new_data`
            ml_new_data = pd.DataFrame({"date": agent_output["date_target"]})

            # Step 2: Fetch Wikipedia Summary
            stock_name = agent_output["stock_symbol"]
            self.logger.info(f"Fetching Wikipedia summary for: {stock_name}")
            wikipedia_summary = self.fetch_wikipedia_data(stock_name)

            # Step 3: Execute Gradient Boosting Workflow
            self.logger.info("Executing machine learning workflow...")
            mse, predictions = self.workflow.execute_workflow(ml_new_data)
            self.logger.info(f"Workflow completed. MSE: {mse}, Predictions: {predictions}")

            # Step 4: Generate Final Response
            self.logger.info("Generating detailed response...")
            response = self.generate_response(stock_name, wikipedia_summary, mse, predictions)

            # Step 5: Return enhanced agent_output
            agent_output_with_response = {
                **agent_output,  # Include all fields from the original agent_output
                "generative_response": response,  # Add the generative response
            }
            self.logger.info("StockResearchAgent workflow completed successfully.")
            return agent_output_with_response

        except Exception as e:
            self.logger.error(f"Error in StockResearchAgent workflow: {e}")
            return {
                **agent_output,  # Preserve the original agent_output fields
                "generative_response": f"Error in StockResearchAgent workflow: {e}",
            }
